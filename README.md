# Social-Detection-AI
AI-driven Deep Machine Learning Model
This system is place to manage data for the construction of learning algorithms using high variability structured data from various external sources. The data management system is the most important core subsystem of any learning model. First we collect large volumes of representative data, which in this case, I have the APIs for Twitter, Instagram, Facebook, Telegram, Reddit, VK ,Facebook real-time posts feeds and historical dataset's of post's and comments. The source code in Python is volumnous, longer than usual. The data processing, synthetic data augmentation, preprocessing, dataset combining and analysis of the quality and accuracy of the dataset and metadata are critical core requirements. Data pipelines are used the dedicated live streams. The training data is broken down into manageable datasets that are considered small. The training datasets need to be ten times the number of parameters of the model, this model has 1 million parameters so I needed 10 million data points, each data point is fairly large because I am using a image fusion technique that layers different frames of images on top of eachhother and fuses them together to get a clearer image with depth of field and variable exposures.
